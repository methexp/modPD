---
editor_options:
  chunk_output_type: console
output:
  pdf_document: default
  html_document: default
---

```{r prepare_variables, include=FALSE, echo = FALSE, warning=FALSE}

knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE)
options(scipen=1, digits=2)

#library("papaja")
library(kableExtra)
#library(stringr)
library(afex)
#remotes::install_github("debruine/bfrr")
library(bfrr)
library(dplyr)
library(effectsize)
set_sum_contrasts()

#function to display results from Bayesian analyses conducted with the package bfrr
printBFRR <- function(bf, RR=TRUE){
  result = paste0(" $BF_{H1: ", bf$H1_model, "}=$ ", ifelse((bf$BF>999)|(bf$BF<.001), format(bf$BF, scientific=TRUE), format(bf$BF, digits=2)))
  if(RR) {
    steps <- length(bf$rr_data$SD)
    maxSD <- ifelse(bf$RR$sd[2]==bf$rr_data$SD[steps], "> max", bf$RR$sd[2])
    result <- paste0(result, " (Robustness Region: ", bf$RR$sd[1], ", ", maxSD, ")" )
  }
  #print(result) # use for debugging in the console
  result
}

# load data

load(file="./data/modPD1.RData")
d1 <- subset(d1, Condition !="Exclusion")
n1 <- length(unique(d1$Subject))

# prepare variables

d1$Valence <- d1$typUS
d1$`Pairing`[d1$typCS=="neutral"] <- "paired" 
d1$`Pairing`[d1$typCS=="neg" | d1$typCS=="pos"] <- "nonpaired"
d1p <- subset(d1, Pairing=="paired")
d1np <- subset(d1, Pairing=="nonpaired")
d1$`Evaluative change` <- d1$postrating - d1$prerating
d1$`TBS Set` <- d1$pdset

d1$pdcor <- FALSE
d1$pdcor[d1$pdval == "pleasant" & d1$typUS == "pos"] <- TRUE
d1$pdcor[d1$pdval == "unpleasant" & d1$typUS == "neg"] <- TRUE
d1$pdcor_ <- as.numeric(d1$pdcor)

```


## Results

We first report results of a manipulation check (i.e., whether our study produced EC effects).
The responses on the novel TBS task are analyzed next, first assessing its validity (i.e., whether the memory and attitude manipulations were adequately reflected in the responses), and then testing for EC without memory as well as the attitude-as-information bias. In the Appendix, we report additional results on the proportions of Memory and Attitude-set judgments and on the proportions of valence memory accuracy in each response set.

<!-- Third, we related the responses on the novel task to evaluative ratings. -->

<!-- ### Manipulation checks -->

<!-- Evaluations and memory judgments as a function of experimental factors -->
<!-- Evaluations by Time (pre-post), Pairing, and Valence -->
<!-- Memory by Pairing and Valence -->

### Evaluative conditioning

Evaluative change was computed as post-learning evaluation minus pre-learning evaluation and submitted to a 2 (Valence) x 2 (Pairing) repeated-measures ANOVA.
Figure \@ref(fig:ec1appendix) shows the results.

```{r ec1appendix, fig.cap="EC effects (pre-post evaluative changes) as a function of Valence and Pairing"}

#par(mfrow=c(1,2))
par(cex = 1.0)

ec1 <- aov_ez(data=d1, id="Subject", dv="Evaluative change", within=c("Valence","Pairing"), fun_aggregate = mean)
ec1_out <- apa_print(ec1)

apa_beeplot(data=d1, id="Subject", dv="Evaluative change", factors=c("Pairing","Valence"), intercept=0, ylim=c(-25,25))

## EC for M vs. A
d1MA <- subset(d1, typCS=="neutral" & Pairing=="paired")
ec_MA <- aov_ez(data=d1MA, id="Subject", dv="Evaluative change", within=c("Valence","pdset"), fun_aggregate = mean)
#apa_beeplot(data=d1MA, id="Subject", dv="Evaluative change", factors=c("pdset","Valence"), intercept=0, ylim=c(-25,25))

d1M <- subset(d1, typCS=="neutral" & pdset=="Memory" & Pairing=="paired")
d1A <- subset(d1, typCS=="neutral" & pdset=="Attitude" & Pairing=="paired")
ec_1M <- aov_ez(data=d1M, id="Subject", dv="Evaluative change", within=c("Valence"), fun_aggregate = mean)
ec_1A <- aov_ez(data=d1A, id="Subject", dv="Evaluative change", within=c("Valence"), fun_aggregate = mean)
#apa_beeplot(data=d1A, id="Subject", dv="Evaluative change", factors=c("Valence"), intercept=0, ylim=c(-25,25))

```

EC was affected by Valence, `r ec1_out$full_result$Valence`, Pairing, `r ec1_out$full_result$Pairing`, as well as, most strongly, their interaction, `r ec1_out$full_result$Valence_Pairing`.
For nonpaired CSs, pre-post changes reflected the statistical artifact of regression to the mean: 
The CSs with most extremely positive pre-ratings became less positive, and the CSs with most extremely negative pre-ratings became less negative.
For paired CSs, pre-post evaluative changes reflected US valence (i.e., an EC effect): 
Those paired with positive CSs became more positive, while those paired with negative USs became more negative.
Interestingly, there was an asymmetry, with the positive larger than the negative shift.

### Validation of the Two-button-sets procedure

To show that the modified task adequately assesses metamemory judgments of CS-US pairings, and attitudes for cases in which participants do not remember CS-US pairings, we analyzed whether (1) pairing affects participants' Memory-set reports (which we expected to differ between paired versus nonpaired control CSs); (2) those memory reports are largely accurate; and (3) participants' pre-rated attitudes are consistently reflected in the Attitude button responses.


```{r freqtable}

## frequencies

### Set selection: Mem vs. Att

p <- with(subset(d1, Pairing=="paired"), table(pdset)) 
np <- with(subset(d1, Pairing=="nonpaired"), table(pdset)) 
p_ <- c(rep(paste0(p[1], " (", printp(p[1]/sum(p[1:2]),2),")"),2)
        , rep(paste0(p[2], " (", printp(p[2]/sum(p[1:2]),2),")"),2))
np_ <- c(rep(paste0(np[1], " (", printp(np[1]/sum(np[1:2]),2),")"),2)
        , rep(paste0(np[2], " (", printp(np[2]/sum(np[1:2]),2),")"),2))

p_ <- c(p[1], paste0(" (", printp(p[1]/sum(p[1:2]),2),")")
        , p[2], paste0(" (", printp(p[2]/sum(p[1:2]),2),")"))
np_ <- c(np[1], paste0(" (", printp(np[1]/sum(np[1:2]),2),")")
        , np[2], paste0(" (", printp(np[2]/sum(np[1:2]),2),")"))

## pleas/unpleas

ppos <- with(subset(d1, Pairing=="paired" & Valence=="pos"), table(pdset, pdval)) # pdresp: 1,3=pleas, 2,4=unpl
ppos_ <- c(ppos[1,1], ppos[1,2], ppos[2,1], ppos[2,2])

pneg <- with(subset(d1, Pairing=="paired" & Valence=="neg"), table(pdset, pdval)) # pdresp: 1,3=pleas, 2,4=unpl
pneg_ <- c(pneg[1,1], pneg[1,2], pneg[2,1], pneg[2,2])

nppos <- with(subset(d1, Pairing=="nonpaired" & Valence=="pos"), table(pdset, pdval)) # pdresp: 1,3=pleas, 2,4=unpl
nppos_ <- c(nppos[1,1], nppos[1,2], nppos[2,1], nppos[2,2])

npneg <- with(subset(d1, Pairing=="nonpaired" & Valence=="neg"), table(pdset, pdval)) # pdresp: 1,3=pleas, 2,4=unpl
npneg_ <- c(npneg[1,1], npneg[1,2], npneg[2,1], npneg[2,2])

ppos__ <- c( paste0(ppos_[1], " (", printp(ppos_[1]/sum(ppos_[1:2], pneg_[1:2]),digits = 2),")")
            ,paste0(ppos_[2], " (", printp(ppos_[2]/sum(ppos_[1:2], pneg_[1:2]),digits = 2),")")
            ,paste0(ppos_[3], " (", printp(ppos_[3]/sum(ppos_[3:4], pneg_[3:4]),digits = 2),")")
            ,paste0(ppos_[4], " (", printp(ppos_[4]/sum(ppos_[3:4], pneg_[3:4]),digits = 2),")"))

pneg__ <- c( paste0(pneg_[1], " (", printp(pneg_[1]/sum(ppos_[1:2], pneg_[1:2]),digits = 2),")")
            ,paste0(pneg_[2], " (", printp(pneg_[2]/sum(ppos_[1:2], pneg_[1:2]),digits = 2),")")
            ,paste0(pneg_[3], " (", printp(pneg_[3]/sum(ppos_[3:4], pneg_[3:4]),digits = 2),")")
            ,paste0(pneg_[4], " (", printp(pneg_[4]/sum(ppos_[3:4], pneg_[3:4]),digits = 2),")"))

nppos__ <- c(paste0(nppos_[1], " (", printp(nppos_[1]/sum(nppos_[1:2], npneg_[1:2]),digits = 2),")")
            ,paste0(nppos_[2], " (", printp(nppos_[2]/sum(nppos_[1:2], npneg_[1:2]),digits = 2),")")
            ,paste0(nppos_[3], " (", printp(nppos_[3]/sum(nppos_[3:4], npneg_[3:4]),digits = 2),")")
            ,paste0(nppos_[4], " (", printp(nppos_[4]/sum(nppos_[3:4], npneg_[3:4]),digits = 2),")"))

npneg__ <- c(paste0(npneg_[1], " (", printp(npneg_[1]/sum(nppos_[1:2], npneg_[1:2]),digits = 2),")")
            ,paste0(npneg_[2], " (", printp(npneg_[2]/sum(nppos_[1:2], npneg_[1:2]),digits = 2),")")
            ,paste0(npneg_[3], " (", printp(npneg_[3]/sum(nppos_[3:4], npneg_[3:4]),digits = 2),")")
            ,paste0(npneg_[4], " (", printp(npneg_[4]/sum(nppos_[3:4], npneg_[3:4]),digits = 2),")"))

## chisq indep tests

memsubj_test <- chisq.test(matrix(c(p,np), nrow=2))
memacc_test <- chisq.test(matrix(c(ppos[1,1:2], pneg[1,1:2]), nrow=2))
attval_test <- chisq.test(matrix(c(nppos[2,], npneg[2,]), nrow=2))
ec_wo_mem_test <- chisq.test(matrix(c(ppos[2,], pneg[2,]), nrow=2))
consbias_test <- chisq.test(matrix(c(nppos[1,1:2], npneg[1,1:2]), nrow=2))

freqtable <- data.frame("M" = c(rep("M",2), rep("A",2))
                       , "CS"=p_ #c(rep(.64,2), rep(.36,2))
                       , "Foil"=np_ #c(rep(.08,2), rep(.92,2))
                       , "Val"=rep(c("+","-"),2)
                       , "CS.p"=ppos__ #c(ppos[1,1], ppos[1,2], ppos[2,3], ppos[2,4])
                       , "CS.n"=pneg__ #c(pneg[1,1], pneg[1,2], pneg[2,3], pneg[2,4])
                       , "Foil.p"=nppos__ #c(nppos[1,1], nppos[1,2], nppos[2,3], nppos[2,4])
                       , "Foil.n"= npneg__ #c(npneg[1,1], npneg[1,2], npneg[2,3], npneg[2,4])
                  )

kbl(freqtable, booktabs=TRUE, align="c", caption="Response frequencies (proportions) on the TBS task, separated by pairing status and US valence (Exp.1). ") %>%
  kable_styling(latex_options = c("scale_down")) %>%
  collapse_rows(columns = 1, latex_hline = "major", valign = "middle")
# Chisq tests are reported for M responses to paired stimuli (memory accuracy), A responses to paired stimuli (EC without memory), M responses to nonpaired stimuli (attitude-consistent guessing), and A responses to nonpaired stimuli (pre-study attitudes).

print_chisq <- function(d){
  paste0("Chisq(",d$parameter,") = ", round(d$statistic,2), ", p = ", printp(d$p.value))
}

```


```{r exp1_logist}


# M/A judgments

## all data
x1. <- glmer(pdset ~ Valence*Pairing + (1 + Valence * Pairing|Subject), family = binomial, data=subset(d1), control=glmerControl(optimizer = "bobyqa"))

## paired
x1.p <- glmer(pdset ~ Valence + (1 + Valence*Pairing|Subject), family = binomial, data=subset(d1), control=glmerControl(optimizer = "bobyqa"))

## nonpaired
x1.u <- glmer(pdset ~ Valence + (1 + Valence|Subject), family = binomial, data=subset(d1np), control=glmerControl(optimizer = "bobyqa"))


# un/pleasant judgments

## all data
x1 <- glmer(pdval ~ Valence*Pairing*pdset + (1 + Valence*Pairing|Subject), family = binomial, data=subset(d1), control=glmerControl(optimizer = "bobyqa"))

## paired
x1p <- glmer(pdval ~ Valence*pdset + (1 + Valence|Subject), family = binomial, data=subset(d1p), control=glmerControl(optimizer = "bobyqa"))

## paired, Memory
x1pM <- glmer(pdval ~ Valence + (1 + Valence|Subject), family = binomial, data=subset(d1p, pdset=="Memory"), control=glmerControl(optimizer = "bobyqa"))

## paired, Attitude
x1pA <- glmer(pdval ~ Valence + (1 + Valence|Subject), family = binomial, data=subset(d1p, pdset=="Attitude"), control=glmerControl(optimizer = "bobyqa"))

## nonpaired
x1np <- glmer(pdval ~ Valence*pdset + (1 + Valence|Subject), family = binomial, data=subset(d1np), control=glmerControl(optimizer = "bobyqa"))

## nonpaired, Memory
x1npM <- glmer(pdval ~ Valence + (1 + Valence|Subject), family = binomial, data=subset(d1np, pdset=="Memory"), control=glmerControl(optimizer = "bobyqa"))

## nonpaired, Attitude
x1npA <- glmer(pdval ~ Valence + (1 + Valence|Subject), family = binomial, data=subset(d1np, pdset=="Attitude"), control=glmerControl(optimizer = "bobyqa"))

```

```{r tbs_correct_proportions, include=FALSE}
#keep only neutral paired CSs and participants that performed the TBS
dat_tbs = subset(d1, Pairing == "paired" & typCS == "neutral") %>% droplevels()
dat_tbs$pdset = as.factor(dat_tbs$pdset)

#for each participant, compute the proportion of correct identifications in the TBS
#meaning, say "positive" if the CS was paired with a positive US, and say "negative if the CS was paired with a negative US
dat_tbs$pdval_pleasant = ifelse(dat_tbs$pdval == "pleasant", "pos", "neg")

dat_tbs$tbs_correct = as.factor(ifelse(dat_tbs$pdval_pleasant == dat_tbs$typUS, "correct", "incorrect"))

#saveRDS(dat_tbs, "data/appendix/appendix_exp1_tbs.RDS")

prop_correct_tbs = dat_tbs %>% 
  group_by(Subject, tbs_correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(Subject) %>% filter(!is.nan(freq))

colnames(prop_correct_tbs) = c("subject", "correct_response", "n_count", "prop")

#proportion correct only for memory buttons in the TBS
prop_correct_tbs_mem = dat_tbs %>% filter(pdset == "Memory") %>%
  group_by(Subject, tbs_correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(Subject) %>% filter(!is.nan(freq))

colnames(prop_correct_tbs_mem) = c("subject", "correct_response", "n_count", "prop")

#tests
t_prop_correct_m = t.test(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"], mu = 0.5)
d_prop_correct_m = cohens_d(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"], mu = .5)

bf_prop_tbs_memory = bfrr(
  sample_mean = mean(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"])-.5, # mean of the sample
  sample_se = sd(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"])/sqrt(length(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
)
#summary(bf_prop_tbs_memory)

#proportion correct only for attitude buttons in the TBS
prop_correct_tbs_att = dat_tbs %>% filter(pdset == "Attitude") %>%
  group_by(Subject, tbs_correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(Subject) %>% filter(!is.nan(freq))

colnames(prop_correct_tbs_att) = c("subject", "correct_response", "n_count", "prop")

#tests
t_prop_correct_a = t.test(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"], mu = 0.5)
d_prop_correct_a = cohens_d(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"], mu = .5)

bf_prop_tbs_att = bfrr(
  sample_mean = mean(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"])-.5, # mean of the sample
  sample_se = sd(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"])/sqrt(length(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
)
#summary(bf_prop_tbs_att)
#plot(bf_prop_tbs_att) 
# --> Evidence for H0s with larger effects (i.e., SD > 25%)
```

Table \@ref(tab:freqtable) shows response frequencies on the TBS task.
The first columns show that participants' metamemory judgments clearly distinguished quite well between paired and nonpaired stimuli, `r print_chisq(memsubj_test)`.
^[A logistic regression confirmed that participants reported more Memory responses for the former than the latter (and vice versa), `r apa_print(x1.)$full_result$Pairing1`. A model with only Pairing predictor performed better than models including the Valence factor and/or the interaction.]

Next, we analyzed the frequencies of "pleasant"/"unpleasant" responses.
They varied as a function of Valence, `r apa_print(x1)$full_result$Valence1`, and this effect was modulated by a two-way interaction with Pairing, `r apa_print(x1)$full_result$Valence1_Pairing1`, as well as its three-way interaction with Response Set (Memory vs. Attitude), `r apa_print(x1)$full_result$Valence1_Pairing1_pdset1`.
Separate analyses for paired and nonpaired stimuli showed, for both item types, effects of Valence (paired: `r apa_print(x1p)$full_result$Valence1`; nonpaired: `r apa_print(x1np)$full_result$Valence1`).
Importantly, they also showed interactions of Valence with Response-Set (paired: `r apa_print(x1p)$full_result$Valence1_pdset1`; nonpaired: `r apa_print(x1np)$full_result$Valence1_pdset1`), indicating that Valence differentially affects Memory and Attitude responses. 
We therefore investigated the effect of Valence separately for each of the four subsets of the Pairing (paired CS vs. nonpaired foil) x Response Set (Memory vs. Attitude).

The corresponding aggregate counts are given in the four 2-by-2 quadrants of Table 1 (one for each combination of the Pairing and Mem/Att variables).
The top left quadrant (i.e., Memory judgments for paired stimuli) is relevant for evaluating accuracy of Memory responses.
It shows frequencies (and proportions, in parentheses) of 'pleasant' (Val:+) and 'unpleasant' (Val:-) responses for CSs that were paired either with positive (CS.p) or negative (CS.n) USs.
Memory judgments for paired stimuli were affected by (i.e., quite accurately reflected) actual US valence, `r apa_print(x1pM)$full_result$Valence1`.
When participants experienced remembering US valence for a paired stimulus, they were accurate in 80% of cases.

The bottom right quadrant (i.e., Attitude judgments for nonpaired stimuli) informs us about the task's ability to reflect pre-experimental attitude.
Nonpaired stimuli (i.e., those not presented together with USs) were selected to be either clearly positive or negative for a given participant.
Attitude judgments for nonpaired valent stimuli were strongly influenced by (i.e., quite accurately reflected) participants' pre-study attitudes towards these stimuli, `r  apa_print(x1npA)$full_result$Valence1`.
Participants consistently reported the attitude corresponding to their pre-study ratings in 95% of cases.

So far, the results show that the TBS task adequately reflected experimental manipulations:
Participants' metamemory judgments were able to separate paired from nonpaired stimuli; Memory-set judgments for paired CSs were largely accurate; and Attitude-set judgments reflected participants' attitudes quite well.


The remaining two quadrants inform us about two relations between EC and memory:
EC without remembering US valence (bottom-left quadrant), and attitude-as-information bias (top-right quadrant).


### Is evaluative conditioning observed without remembering the CS-US pairings?

The bottom left quadrant (Attitude-set judgments for paired stimuli) is relevant to the issue of EC in the absence of feelings of remembering:
An Attitude-set judgment implies the metacognitive absence of remembering US valence. 
For paired CSs, the Attitude-set responses should reflect evaluations in the absence of remembering US valence.
We saw above that Valence affected responses to paired CSs, and that this effect was modulated by an interaction with Response-Button set:
Whereas the effect of Valence was found for Memory-set responses (see above), it was absent from Attitude-set responses, `r apa_print(x1pA)$full_result$Valence1`. 
Thus, as reflected in Table 1, there was no significant EC in the absence of feelings of remembering US valence.

Because failing to find a significant effect is not evidence for the absence of an effect, we additionally conducted a Bayesian analysis that allows quantifying the evidence for the null hypothesis of no effect. 
Specifically, for Attitude-set judgments on paired neutral CSs, we computed a Bayes Factor (BF) on the proportions of responses in line with US Valence. 
We modeled the distribution of true effect sizes under the H1 as a half-normal distribution with an SD of 15% (similar to Waroquier et al., 2020).^[Waroquier et al (2020) chose this value based on Stahl et al. (2009) who found valence memory performance roughly 15% above the 50% chance level; we assume here that effects on memory and evaluations should be comparable under a single-process account.] 
For each *BF*, noted $BF_{H1:N(0, .15)}$, we report the Robustness Region to indicate the range of *SD*s of the *H1* distribution that support the same conclusion as the reported *BF*; the *SDs* ranged from zero to the maximal value of the scale (i.e., 100%).
We used conventional cut-offs to interpret *BF*s (e.g., Dienes, 2014): 
A *BF* above 3 yields evidence for *H1* compared with *H0*, while a *BF* below 1/3 yields evidence for *H0*. 
A *BF* between 1/3 and 3 would count as anecdotal evidence in either direction, and indicates inconclusive data (i.e., no evidence for either hypothesis).

The Bayes Factor analyses yielded inconclusive evidence for or against above-chance responses in line with US valence (*M =* `r mean(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"])`; *SD =* `r sd(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"])`), `r printBFRR(bf_prop_tbs_att)`.
In sum, there was no significant EC effect for Attitude-set judgments, but we cannot conclude from this finding that there is evidence for no EC in the absence of feelings of remembering US valence.

### Is there evidence for an affect-as-information bias?

Finally, we examined whether Memory-set responses were systematically affected by participants' attitudes towards nonpaired (but inherently valent) stimuli.
The top-right quadrant of Table 1 (Memory-set judgments for nonpaired stimuli) serves as a test for attitude-consistent guessing.
Most often, nonpaired stimuli were judged 'not remembered', and hence Attitude-set responses were given on the TBS task.
Yet, in those cases that participants falsely 'remembered' that a US had been paired with them (i.e., used the Memory button set), they reported a US valence that tended to be consistent with pre-experimental attitudes, `r apa_print(x1npM)$full_result$Valence1`.
(However, as indicated by the above interaction with Response Set, this effect was smaller than for the Attitude-set judgments.)
In sum, participants indeed showed an attitude-as-information bias on Memory-set responses: 
For a stimulus falsely judged as having been paired with a US, they relied on their evaluation of that stimulus to inform their memory judgments in 73% of cases.
Yet, Memory-set responses did not reflect attitudes as strongly as did Attitude-set responses. 
This suggests that participants may be able to influence the degree to which they allow pre-existing attitudes to inform their judgments.

Taken together, the results of the TBS task appropriately reflected the memory and attitude manipulations. 
Furthermore, we did not find the EC effect in the absence of feelings of remembering US valence.
In addition, an effect of attitude-as-information was found in Memory-set responses for nonpaired stimuli.
