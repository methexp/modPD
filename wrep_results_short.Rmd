---
output:
  pdf_document:
  html_document:
    fig_caption: yes
    keep_md: yes
editor_options:
  chunk_output_type: console
---

```{r set, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,cache=TRUE,message=FALSE,warning=FALSE)
options(scipen=1, digits=2)

#Load (or install and load) packages
require(pacman)
p_load('tidyverse', 'psych', 'effectsize', 'afex', 'bfrr', 'papaja', 'kableExtra') 

#function to display results from Bayesian analyses conducted with the package bfrr
printBFRR <- function(bf, RR=TRUE){
  result = paste0(" $BF_{H1: ", bf$H1_model, "}=$ ", ifelse((bf$BF>999)|(bf$BF<.001), format(bf$BF, scientific=TRUE), format(bf$BF, digits=2)))
  if(RR) {
    steps <- length(bf$rr_data$SD)
    maxSD <- ifelse(bf$RR$sd[2]==bf$rr_data$SD[steps], "> max", bf$RR$sd[2])
    result <- paste0(result, " (Robustness Region: ", bf$RR$sd[1], ", ", maxSD, ")" )
  }
  #print(result) # use for debugging in the console
  result
}

#read the dataset we created in a previous R script
dat = readRDS("data/data_wrep_final.RDS") #40 rows for each participant (because 40 different CSs)

#the "eval_condition" factor is not very helpful as it confounds two factors (order and tasks); separate the two
dat = dat %>% separate(eval_condition, c("eval_task","eval_task_order"), sep = "_ratings_")

#some factors are integer or character variables in the dataset; make them factors
dat$subject = as.factor(dat$subject)
dat$us_valence = as.factor(dat$us_valence)
dat$eval_task = as.factor(dat$eval_task)
dat$eval_task_order = as.factor(dat$eval_task_order)
dat$failed_check_tbs = as.factor(dat$failed_check_tbs)
dat$failed_check_vma = as.factor(dat$failed_check_vma)
dat$failed_check_3bs = as.factor(dat$failed_check_3bs)
```

```{r, exclude_instruction_checks, include=FALSE}
#exclude participants that failed instruction-understanding checks

#how much participants failed the tbs, vma, or 3bs?
# table(dat$failed_check_tbs)/40
# table(dat$failed_check_vma)/40
# table(dat$failed_check_3bs)/40

dat = dat %>% filter((failed_check_vma=="not_failed" & eval_task == "Wrep") |
                    (failed_check_3bs == "not_failed" & eval_task == "3BS_study") |
                    (failed_check_tbs == "not_failed" & eval_task == "TBSrep")
                    )

addmargins(table(dat$eval_task)/40)

length(unique(dat$subject)) # N of participants after instruction-understanding check exclusion
```

```{r count, include=FALSE}
#exclude participants declaring they did not take their responses seriously
##or did not pay attention
dat = dat %>% filter(pay_attention != 0 & serious != 0) %>% droplevels() #drop level to remove excluded ppts
length(unique(dat$subject)) # N of participants after exclusion
#185 participants kept after data exclusion 

#How many participant in each evaluative condition after data exclusion?
addmargins(table(dat$eval_task)/40)
```

<!-- We used both frequentist and Bayesian analyses. We computed Bayes Factors (BF) to quantify the evidence for the alternative (H1) against the null (H0) hypothesis.  -->

<!-- In the Two-buttons-sets (TBS) procedure, similar to the Bayesian analyses conducted in Experiments 1 and 2, we computed BF on the proportions of responses in line with US Valence separately in the Memory and Attitude responses buttons sets.  -->

<!-- For the manipulation check and analyses we conducted on the Valence Memory Attribution (VMA) task and the Three-attribution, continuous evaluative ratings (3ACE) task, we modeled H1 as a half-normal distribution with an SD of 23.5 evaluative rating units when testing evaluative conditioning (EC) effects with pre-post evaluative change scores (similar to Waroquier et al., 2020; they chose this value based on the results of studies similar to theirs). Similar to analyses on the TBS, we calculated the proportions of VMA and 3ACE responses that were in line with US Valence separately for each attribution (memory; intuition; random guessing) and tested them against the chance level with BF. -->

<!-- ## Main findings -->

We first report results of a manipulation check (i.e., whether there was a robust EC effect).
Next, we turn to the results of the TBS task, focusing on whether the absence of EC without feelings of remembering US valence is replicated when using a simplified design. 
Subsequently, we report EC effects for the different attributions in the VMA and 3ACE tasks.
In the Appendix, we report additional results on the proportions of Memory/Attitude responses (in the TBS task), attributions (in the VMA and 3ACE tasks), and on valence memory accuracy in each response set for each task.

### Evaluative conditioning

As a manipulation check, we first tested whether there was an EC effect overall, based on the final total sample (*N =* `r length(unique(dat$subject))`).
An ANOVA of the pre-post evaluative change scores tested whether they were influenced by US Valence (see Figure \@ref(fig:plotevalchange)), and whether this influence was modulated by task or order condition.  

```{r eval_change, include=FALSE}
####
#EVALUATIVE CHANGE IN GENERAL
####

#compute evaluative change scores
#first, rescale the prerating and postrating scales (0 to 400 instead of -200 to 200)
dat$scale_prerating = dat$scale_prerating + 200
dat$scale_postrating = dat$scale_postrating + 200

#compute the difference between pre- and post-ratings for each CS
dat_eval_change = dat %>% 
  group_by(subject, c, u, us_valence) %>% 
  summarise(eval_change_score = scale_postrating - scale_prerating)

#add this evaluative change score to the dataset
dat = full_join(dat, dat_eval_change
                , by = c("subject"="subject", "us_valence"="us_valence", "c"="c", "u"="u"))

#compute mean evaluative change scores for each participant as a function of US Valence 
dat_ev = dat %>%
  group_by(subject, us_valence) %>%
  summarize(mean_eval_change = mean(eval_change_score))

#check data distribution
# plot(density(dat_ev$mean_eval_change[dat_ev$us_valence=="positive"]))
# plot(density(dat_ev$mean_eval_change[dat_ev$us_valence=="negative"]))
```

```{r eval_change_test, include=FALSE}
dat_ = dat %>%
  group_by(subject, us_valence) %>%
  mutate(mean_eval_change = mean(eval_change_score))
mod1 = aov_ez(dat_
              ,id = "subject"
              ,dv = "mean_eval_change"
              ,within = "us_valence"
              ,between = c("eval_task","eval_task_order")
)

# mod1_print = apa_print(mod1)

# apa_table(
#   mod1_print$table
#   ,caption = "Repeated-measures ANOVA: Evaluative change scores as a function of US Valence irrespective of Task condition"
# )

# Descriptive statistics: evaluative change scores as a function of US Valence
# knitr::kable(describeBy(dat_ev$mean_eval_change, dat_ev$us_valence, mat = TRUE), digits = 2)

#to compute Bayes Factors similarly to how Waroquier et al. did, we will compute the difference of evaluative change scores between positive and negative USs

#first, make a wide data frame so that we can compute the differences
dat_ev_wide = dat_ev %>% pivot_wider(names_from = "us_valence"
                                     ,values_from = "mean_eval_change")

#compute the difference
dat_ev_wide$diff_overall = dat_ev_wide$positive-dat_ev_wide$negative

#use the bfrr package to compute Bayes Factors. The package is helpful because it allows one to
##conveniently specify H1 and to compute robustness regions, as in Waroquier et al.
bf_ev_overall = bfrr(
  sample_mean = mean(dat_ev_wide$diff_overall), # mean of the sample
  sample_se = sd(dat_ev_wide$diff_overall)/sqrt(length(dat_ev_wide$diff_overall)), # SE of the sample
  sample_df = length(dat_ev_wide$diff_overall) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = 23.5, #as in Waroquier et al.
  tail = 1, #one sided 
  criterion = 3, 
  rr_interval = list(
    # mean = c(-2, 2),
    sd = c(0, 200)
  )
)
```

```{r plotevalchange, fig.cap="Pre-post evaluative change as a function of US Valence and Task condition. Dots are the individual observations, and error bars are the 95% Confidence Intervals. *Note:* TBS = Two-buttons-sets procedure; VMA = Valence Memory Attribution task; 3ACE = Three-attribution, continuous evaluative ratings task."}
dat$task = as.factor(recode(dat$eval_task, "TBSrep"="TBS"
       ,"Wrep"="VMA"
       ,"3BS_study"="3ACE"))

dat$task = fct_relevel(dat$task, "TBS", "VMA", "3ACE")

dat$`US Valence` = dat$us_valence

#visualize the data
apa_beeplot(data=dat, id="subject", dv="eval_change_score", factors=c("task","US Valence"), intercept =0, use = "all.obs", ylim=c(-50,50),
            xlab = "Task"
            ,ylab = "Evaluative change score")
```

Overall, we found only an effect of US Valence (i.e., an EC effect): 
Pre-post evaluative change scores were higher for CSs paired with positive than negative USs, `r apa_print(mod1)$full_result$us_valence` (all other effects were not significant). 

### Two-buttons-sets procedure

```{r tbs_count, include=FALSE}
####
#TBS PROCEDURE
####

#keep only participants that performed the TBS
dat_tbs = dat %>% filter(eval_task == "TBSrep") %>% droplevels()

##alternatively, we can keep only participants that performed the TBS as the first or second evaluative task (the TBS condition)
#dat_tbs = dat %>% filter(eval_task == "TBSrep") %>% droplevels()

#length(unique(dat_tbs$subject)) #127 participants

#recode the tbs response into two variables: whether participant gave a positive or negative response (tbs_val_resp)
##and whether participants used the memory of the attitude button set (tbs_button_resp)
dat_tbs$response_tbs = str_remove(dat_tbs$response_tbs, "_response")
dat_tbs = dat_tbs %>% separate(response_tbs, c("tbs_val_resp","tbs_button_resp"))

dat_tbs$tbs_button_resp = as.factor(dat_tbs$tbs_button_resp)

#count memory and attitude button responses
# n_attrib_tbs = dat_tbs %>% 
#   group_by(subject, tbs_button_resp, .drop=FALSE) %>% tally()
# colnames(n_attrib_tbs) = c("subject", "attrib_buttons", "n_attrib_tbs")

#at the aggregated level
#knitr::kable(describeBy(n_attrib_tbs$n, n_attrib_tbs$tbs_button_resp, mat=TRUE), digits=2)
```

```{r tbs_correct_proportions_overall, include=FALSE}
#for each participant, compute the proportion of correct identifications in the TBS
#meaning, say "positive" if the CS was paired with a positive US, and say "negative if the CS was paired with a negative US
dat_tbs$tbs_correct = as.factor(ifelse(substr(dat_tbs$us_valence, 1, 3) == dat_tbs$tbs_val_resp, "correct", "incorrect"))

#saveRDS(dat_tbs, "data/appendix/appendix_exp3_tbs.RDS")

prop_correct_tbs = dat_tbs %>% 
  group_by(subject, tbs_correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(subject) %>% filter(!is.nan(freq))

colnames(prop_correct_tbs) = c("subject", "correct_response", "n_count", "prop")

#at the aggregated level
#knitr::kable(describe(prop_correct_tbs$prop[prop_correct_tbs$correct_response=="correct"]), digits=2)

#tests
t_prop_correct_o = t.test(prop_correct_tbs$prop[prop_correct_tbs$correct_response=="correct"], mu = 0.5)
d_prop_correct_o = cohens_d(prop_correct_tbs$prop[prop_correct_tbs$correct_response=="correct"], mu = .5)

bf_prop_overall_tbs = bfrr(
  sample_mean = mean(prop_correct_tbs$prop[prop_correct_tbs$correct_response=="correct"])-.5, # mean of the sample
  sample_se = sd(prop_correct_tbs$prop[prop_correct_tbs$correct_response=="correct"])/sqrt(length(prop_correct_tbs$prop[prop_correct_tbs$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_tbs$prop[prop_correct_tbs$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
)
#summary(bf_prop_overall_tbs)
```

```{r tbs_correct_proportions_memory, include=FALSE}
#proportion correct only for memory buttons in the TBS
prop_correct_tbs_mem = dat_tbs %>% filter(tbs_button_resp == "memory") %>%
  group_by(subject, tbs_correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(subject) %>% filter(!is.nan(freq))

colnames(prop_correct_tbs_mem) = c("subject", "correct_response", "n_count", "prop")

#at the aggregated level
#knitr::kable(describe(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"]), digits=2)

#tests
t_prop_correct_m = t.test(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"], mu = 0.5)
d_prop_correct_m = cohens_d(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"], mu = .5)

bf_prop_tbs_memory = bfrr(
  sample_mean = mean(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"])-.5, # mean of the sample
  sample_se = sd(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"])/sqrt(length(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
)
#summary(bf_prop_tbs_memory)
```

```{r tbs_correct_proportions_attitudes, include=FALSE}
#proportion correct only for attitude buttons in the TBS
prop_correct_tbs_att = dat_tbs %>% filter(tbs_button_resp == "attitude") %>%
  group_by(subject, tbs_correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(subject) %>% filter(!is.nan(freq))

colnames(prop_correct_tbs_att) = c("subject", "correct_response", "n_count", "prop")

#at the aggregated level
#knitr::kable(describe(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"]), digits=2)

#tests
t_prop_correct_a = t.test(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"], mu = 0.5)
d_prop_correct_a = cohens_d(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"], mu = .5)

bf_prop_tbs_att = bfrr(
  sample_mean = mean(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"])-.5, # mean of the sample
  sample_se = sd(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"])/sqrt(length(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
)
#summary(bf_prop_tbs_att)
```

```{r tbs_table}
## frequencies

frq_table = dat_tbs %>% 
    group_by(tbs_button_resp, tbs_val_resp, us_valence) %>% 
    summarise(n = n())

frq_table_mem = subset(frq_table, tbs_button_resp=="memory")
frq_table_mem_pos = subset(frq_table, tbs_button_resp=="memory" & tbs_val_resp=="pos")
frq_table_mem_neg = subset(frq_table, tbs_button_resp=="memory" & tbs_val_resp=="neg")

frq_table_att = subset(frq_table, tbs_button_resp=="attitude")
frq_table_att_pos = subset(frq_table, tbs_button_resp=="attitude" & tbs_val_resp=="pos")
frq_table_att_neg = subset(frq_table, tbs_button_resp=="attitude" & tbs_val_resp=="neg")

tbs_table = data.frame(list(expand.grid(
  Val = c("+", "-"),
  Set = c("Memory", "Attitude")),
  Response = c(sum(frq_table_mem$n),
               paste0("(", round(sum(frq_table_mem$n)/sum(frq_table_mem$n, frq_table_att$n),digits = 2), ")"),
               sum(frq_table_att$n),
               paste0("(", round(sum(frq_table_att$n)/sum(frq_table_mem$n, frq_table_att$n),digits = 2), ")")),
  CS.p = c(paste0(frq_table_mem_pos$n[frq_table_mem_pos$us_valence=="positive"], " (", round(frq_table_mem_pos$n[frq_table_mem_pos$us_valence=="positive"]/sum(frq_table_mem$n),digits = 2), ")"),
           paste0(frq_table_mem_neg$n[frq_table_mem_pos$us_valence=="positive"], " (", round(frq_table_mem_neg$n[frq_table_mem_neg$us_valence=="positive"]/sum(frq_table_mem$n),digits = 2), ")"),
           paste0(frq_table_att_pos$n[frq_table_mem_pos$us_valence=="positive"], " (", round(frq_table_att_pos$n[frq_table_att_pos$us_valence=="positive"]/sum(frq_table_att$n),digits = 2), ")"),
           paste0(frq_table_att_neg$n[frq_table_mem_pos$us_valence=="positive"], " (", round(frq_table_att_neg$n[frq_table_att_neg$us_valence=="positive"]/sum(frq_table_att$n),digits = 2), ")")),
  CS.n = c(paste0(frq_table_mem_pos$n[frq_table_mem_pos$us_valence=="negative"], " (", round(frq_table_mem_pos$n[frq_table_mem_pos$us_valence=="negative"]/sum(frq_table_mem$n),digits = 2), ")"),
           paste0(frq_table_mem_neg$n[frq_table_mem_pos$us_valence=="negative"], " (", round(frq_table_mem_neg$n[frq_table_mem_neg$us_valence=="negative"]/sum(frq_table_mem$n),digits = 2), ")"),
           paste0(frq_table_att_pos$n[frq_table_mem_pos$us_valence=="negative"], " (", round(frq_table_att_pos$n[frq_table_att_pos$us_valence=="negative"]/sum(frq_table_att$n),digits = 2), ")"),
           paste0(frq_table_att_neg$n[frq_table_mem_pos$us_valence=="negative"], " (", round(frq_table_att_neg$n[frq_table_att_neg$us_valence=="negative"]/sum(frq_table_att$n),digits = 2), ")"))
))

tbs_table =  tbs_table[, c(2, 3, 1, 4, 5)]

kbl(tbs_table, booktabs=TRUE, align="c", caption="Exp.3, TBS response frequencies (proportions).", label="freqtable3") %>%
  kable_styling(latex_options = c("scale_down")) %>%
  collapse_rows(columns = 1, latex_hline = "major", valign = "middle")
```

```{r tbs_chisq_memory, include=FALSE}
tab_chisq = as.matrix(rbind(c(475,158),c(117, 431)))
khi_tbs = chisq.test(tab_chisq)
khi_p <- ifelse(khi_tbs$p.value > .001, paste0("*p* = ", khi_tbs$p.value), "*p* < .001")
```

We conducted analyses with data from participants in the TBS task condition (*n =* `r length(unique(dat_tbs$subject))`). 
As in Experiments 1 and 2, the responses on the TBS task are first given in a tabulated form (Table \@ref(tab:freqtable3)).

First, we tested accuracy of Memory set responses (i.e., the accuracy of participants' US Valence reports when they felt they remembered US Valence). 
The first two rows of the table ("Memory" responses; see columns *CS.p* and *CS.n* for responses on CS paired with positive and negative US, respectively) show that participants accurately distinguished between CS that were paired with positive and negative US when they made a Memory response, $\chi^2$(`r khi_tbs$parameter`) = `r khi_tbs$statistic`, `r khi_p` (see also below).

```{r}
# Memory responses were above the chance level (50%), showing that participants were globally accurate when reporting US Valence they felt they remembered (*M =* `r mean(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"])`; *SD =* `r sd(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"])`), `r apa_print(t_prop_correct_m)$statistic`, *d =* `r d_prop_correct_m$Cohens_d`, $BF_{H(0, 15\%)}=$ `r bf_prop_tbs_memory$BF`. 
```

```{r}
#### Valence memory in the TBS task

# We conducted analyses with data from participants in the TBS task condition (*n =* `r length(unique(dat_tbs$subject))`). 
# We tested whether valence memory performance was higher than chance (50%) overall and separately for each response buttons set. 
# Overall, valence memory as estimated in the TBS task was above chance (*M =* `r mean(prop_correct_tbs$prop[prop_correct_tbs$correct_response=="correct"])`; *SD =* `r sd(prop_correct_tbs$prop[prop_correct_tbs$correct_response=="correct"])`), `r apa_print(t_prop_correct_o)$statistic`, *d =* `r d_prop_correct_o$Cohens_d`, $BF_{H(0, 15\%)}=$ `r bf_prop_overall_tbs$BF`. 
# This was also the case when participants used the "memory" buttons set (*M =* `r mean(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"])`; *SD =* `r sd(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"])`), `r apa_print(t_prop_correct_m)$statistic`, *d =* `r d_prop_correct_m$Cohens_d`, $BF_{H(0, 15\%)}=$ `r bf_prop_tbs_memory$BF`. 
# Importantly, valence memory performance was not different from the chance level for responses on the attitude buttons set (*M =* `r mean(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"])`; *SD =* `r sd(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"])`), `r apa_print(t_prop_correct_a)$statistic`, *d =* `r d_prop_correct_a$Cohens_d`, $BF_{H(0, 15\%)}=$ `r bf_prop_tbs_att$BF`.

```

```{r prepare_plot_tbs, include=FALSE, eval=FALSE}
dat_tbs$tbs_button_resp = fct_relevel(dat_tbs$tbs_button_resp, "memory", "attitude")

dat_tbs_plot = dat_tbs %>%
  group_by(subject, us_valence, tbs_button_resp) %>%
  summarise(mean_eval_change = mean(eval_change_score)) 

dat_tbs_plot_wide = dat_tbs_plot %>% pivot_wider(names_from = us_valence
                                                 ,values_from = mean_eval_change)

dat_tbs_plot_wide$EC_score = dat_tbs_plot_wide$positive - dat_tbs_plot_wide$negative
```

```{r overall_tbs_figure, fig.cap="Difference between evaluative change scores for CS+ and CS- (EC scores) as a function of Response button sets (TBS Task condition). Dots are the individual observations, and error bars are the 95% Confidence Intervals.", eval=FALSE}
apa_beeplot(data=dat_tbs_plot_wide, id="subject", dv="EC_score", factors="tbs_button_resp", intercept =0, use = "all.obs", ylim=c(-200,200), xlab = 'TBS response button set', ylab = 'Evaluative Conditioning effect score')
```

```{r tbs_eval_change_memory, include=FALSE, eval=FALSE}
####
#EVALUATIVE CHANGE AS A FUNCTION OF VALENCE MEMORY ATTRIBUTIONS IN THE TBS TASK
####

###memory button
dat_ev_tbs_memory = dat_tbs %>%  filter(tbs_button_resp == "memory") %>%
  group_by(subject, us_valence) %>%
  summarise(mean_eval_change = mean(eval_change_score)) %>% filter(n() > 1)

mod_memory_tbs = aov_ez(dat_ev_tbs_memory
                                ,id = "subject"
                                ,dv = "mean_eval_change"
                                ,within = "us_valence"
)

# mod_memory_tbs_print = apa_print(mod_memory_tbs)
# 
# apa_table(
#   mod_memory_tbs_print$table
#   ,caption = "Repeated-measures ANOVA: Evaluative change scores as a function of US Valence for CSs that received a memory-buttons set response (TBS task)"
# )
# 
# knitr::kable(describeBy(dat_ev_tbs_memory$mean_eval_change, dat_ev_tbs_memory$us_valence, mat=TRUE), digits=2)

dat_ev_tbs_memory_wide = dat_ev_tbs_memory %>% pivot_wider(names_from = "us_valence"
                              ,values_from = "mean_eval_change")

dat_ev_tbs_memory_wide$diff_overall = dat_ev_tbs_memory_wide$positive-dat_ev_tbs_memory_wide$negative 

dat_ev_tbs_memory_wide = dat_ev_tbs_memory_wide %>% filter(!is.na(diff_overall))

bf_ev_memory_tbs = bfrr(
  sample_mean = mean(dat_ev_tbs_memory_wide$diff_overall), # mean of the sample
  sample_se = sd(dat_ev_tbs_memory_wide$diff_overall)/sqrt(length(dat_ev_tbs_memory_wide$diff_overall)), # SE of the sample
  sample_df = length(dat_ev_tbs_memory_wide$diff_overall) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = 23.5,
  tail = 1,
  criterion = 3, 
  rr_interval = list(
    # mean = c(-2, 2),
    sd = c(0, 200)
  )
)

#summary(bf_ev_memory_tbs)
```

```{r tbs_eval_change_attitude, include=FALSE, eval=FALSE}
###attitude button
dat_ev_tbs_attitude = dat_tbs %>%  filter(tbs_button_resp == "attitude") %>%
  group_by(subject, us_valence) %>%
  summarise(mean_eval_change = mean(eval_change_score)) %>% filter(n() > 1)

mod_attitude_tbs = aov_ez(dat_ev_tbs_attitude
                                  ,id = "subject"
                                  ,dv = "mean_eval_change"
                                  ,within = "us_valence"
)

# mod_attitude_tbs_print = apa_print(mod_attitude_tbs)
# 
# apa_table(
#   mod_attitude_tbs_print$table
#   ,caption = "Repeated-measures ANOVA: Evaluative change scores as a function of US Valence for CSs that received an attitude-buttons set response (TBS task)"
# )
# 
# 
# knitr::kable(describeBy(dat_ev_tbs_attitude$mean_eval_change, dat_ev_tbs_attitude$us_valence, mat=TRUE), digits=2)

dat_ev_tbs_attitude_wide = dat_ev_tbs_attitude %>% pivot_wider(names_from = "us_valence"
                                                                               ,values_from = "mean_eval_change")

dat_ev_tbs_attitude_wide$diff_overall = dat_ev_tbs_attitude_wide$positive-dat_ev_tbs_attitude_wide$negative 

dat_ev_tbs_attitude_wide = dat_ev_tbs_attitude_wide %>% filter(!is.na(diff_overall))

bf_ev_attitude_tbs = bfrr(
  sample_mean = mean(dat_ev_tbs_attitude_wide$diff_overall), # mean of the sample
  sample_se = sd(dat_ev_tbs_attitude_wide$diff_overall)/sqrt(length(dat_ev_tbs_attitude_wide$diff_overall)), # SE of the sample
  sample_df = length(dat_ev_tbs_attitude_wide$diff_overall) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = 23.5,
  tail = 1,
  criterion = 3, 
  rr_interval = list(
    # mean = c(-2, 2),
    sd = c(0, 200)
  )
)

#summary(bf_ev_attitude_tbs)
```

```{r mixed_tbs, include=FALSE}
#mixed-effects logistic regression

dat_tbs$tbs_val_resp_bin = recode(dat_tbs$tbs_val_resp, "pos"=1, "neg"=0)
mixedmod_val = glmer(tbs_val_resp_bin ~ us_valence*tbs_button_resp + (1 + us_valence|subject), family = binomial, data=dat_tbs, control=glmerControl(optimizer = "bobyqa"))

#button set: memory
mixedmod_val_mem = glmer(tbs_val_resp_bin ~ us_valence + (1 + us_valence|subject), family = binomial, data=subset(dat_tbs, tbs_button_resp=="memory"), control=glmerControl(optimizer = "bobyqa"))

#button set: attitude
mixedmod_val_att = glmer(tbs_val_resp_bin ~ us_valence + (1 + us_valence|subject), family = binomial, data=subset(dat_tbs, tbs_button_resp=="attitude"), control=glmerControl(optimizer = "bobyqa"))

#dat_tbs$tbs_button_resp_bin = recode(dat_tbs$tbs_button_resp, "memory"=1, "attitude"=0)
#mixedmod_set = glmer(tbs_button_resp_bin ~ us_valence + (1 + us_valence|subject), family = binomial, data=dat_tbs, control=glmerControl(optimizer = "bobyqa"))

#BFs for proportions separately in the memory and attitudes responses buttons sets
# memBF = proportionBF(y = 475+431
#              ,N = 1181
#              ,p = .5
#              ,rscale = 1/2
# )
# attBF = proportionBF(y = 339+410
#              ,N = 1499
#              ,p = .5
#              ,rscale = 1/2
# )
```

```{r}
# The critical test is whether an EC effect is found when participants lack memory (i.e., when they use the attitude buttons set). The main results are displayed in Figure \@ref(fig:overall_tbs_figure). Both frequentist and Bayesian analyses yielded evidence for an EC effect when participants used the memory buttons set, `r apa_print(mod_memory_tbs)$full_result`, $BF_{H(0, 23.5)}=$ `r bf_ev_memory_tbs$BF`. When participants used the attitude buttons set, the EC effect was not significant and BF yields evidence against the EC effect, `r apa_print(mod_attitude_tbs)$full_result`, $BF_{H(0, 23.5)}=$ `r bf_ev_attitude_tbs$BF`.
```

<!-- ### Is evaluative conditioning observed in the absence of conscious retrieval of the CS-US pairings? -->

To analyze participants' responses in the TBS task, we conducted a mixed-effect logistic regression (random intercepts and slopes for US Valence) with US Valence and Response buttons set as predictors. 
The interaction between US Valence and Response buttons set was significant, `r apa_print(mixedmod_val)$full_result$us_valence1_tbs_button_resp1`. 
We conducted separate analyses at each Response buttons set level to simplify interpretation of the findings. 
When participants used the Memory response buttons set, the US Valence effect was significant, `r apa_print(mixedmod_val_mem)$full_result$us_valence1`, indicating above-chance valence memory accuracy. 

```{r}
#We also found evidence for accurate valence memory in a one-sample *t* test against chance level (i.e., .5) on the proportions of correct responses (*M =* `r mean(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"])`; *SD =* `r sd(prop_correct_tbs_mem$prop[prop_correct_tbs_mem$correct_response=="correct"])`), `r apa_print(t_prop_correct_m)$statistic`, *d =* `r d_prop_correct_m$Cohens_d`, `r printBFRR(bf_prop_tbs_memory)`.
```

In contrast, in the Attitude response buttons set, no significant effect of US Valence was found, `r apa_print(mixedmod_val_att)$full_result$us_valence1`. 
This replicates our previous findings of the absence of an EC effect when participants reported having no US valence memory. 
Importantly, we also found evidence for the absence of an EC effect in a one-sample *t* test against chance level (i.e., .5) on the proportions of TBS responses in line with US valence (*M =* `r mean(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"])`; *SD =* `r sd(prop_correct_tbs_att$prop[prop_correct_tbs_att$correct_response=="correct"])`), which were not significantly different from the chance level, `r apa_print(t_prop_correct_a)$statistic`, *d =* `r d_prop_correct_a$Cohens_d`. 
As in Experiment 2, a Bayesian analysis yielded evidence for no EC effect in the absence of feelings of remembering US valence, `r printBFRR(bf_prop_tbs_att)` (note that this conclusion again holds even for small effects).

### Additional results

Here, we report the results of our attempt to replicate the EC-without-conscious-knowledge findings by Waroquier et al. (2020), who assessed participants' attributions of their valence-memory decisions (i.e., subjective assessments of their knowledge) and found EC effects when participants indicated having only intuitions about US valence or when participants reported randomly guessing.
We also report initial results from a new version of the procedure (i.e., 3ACE) that serves to illustrate how the TBS approach could be further developed by capturing three (rather than two) retrieval experiences, and by assessing evaluations on a continuous rating scale (rather than as a binary choice).

#### Valence Memory Attribution (VMA) task 

```{r vma, include=FALSE}
####
#VMA TASK (whether it was administered first or second) - mimics analyses of Waroquier et al.
####

dat_vma = dat %>% filter(eval_task=="Wrep") %>% droplevels()

#saveRDS(dat_vma, "data/appendix/appendix_exp3_vma.RDS")
```

```{r vma_correct_proportions_overall, include=FALSE}
#for each participant, compute the proportion of correct identifications in the VMA
#meaning, say "positive" if the CS was paired with a positive US, and say "negative if the CS was paired with a negative US
dat_vma$vma_correct = as.factor(ifelse(substr(dat_vma$response_valence_id, 1, 3) == substr(dat_vma$us_valence, 1, 3), "correct", "incorrect"))

prop_correct_vma = dat_vma %>% 
  group_by(subject, vma_correct, .drop=FALSE) %>%  #drop=FALSE to keep "correct" and "incorrect" rows for all participants
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(subject) %>% filter(!is.nan(freq))

#filter "NaN" because it does not make sense to include participants that did not provide responses (concerns mainly "guess" responses)

colnames(prop_correct_vma) = c("subject", "correct_response", "n_count", "prop")

#at the aggregated level
#knitr::kable(describe(prop_correct_vma$prop[prop_correct_vma$correct_response=="correct"]), digits = 2)

#tests
t_prop_vma_o = t.test(prop_correct_vma$prop[prop_correct_vma$correct_response=="correct"], mu = 0.5)
d_prop_vma_o = cohens_d(prop_correct_vma$prop[prop_correct_vma$correct_response=="correct"], mu = .5)

bf_prop_overall = bfrr(
  sample_mean = mean(prop_correct_vma$prop[prop_correct_vma$correct_response=="correct"])-.5, # mean of the sample minus the test value .5
  sample_se = sd(prop_correct_vma$prop[prop_correct_vma$correct_response=="correct"])/sqrt(length(prop_correct_vma$prop[prop_correct_vma$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_vma$prop[prop_correct_vma$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
  )
#summary(bf_prop_overall)
```

```{r vma_correct_proportions_memory, include=FALSE}
#proportion correct only for memory attributions in the VMA
prop_correct_vma_mem = dat_vma %>% filter(attrib_buttons == "memory_attrib_button") %>%
  group_by(subject, vma_correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(subject) %>% filter(!is.nan(freq))

colnames(prop_correct_vma_mem) = c("subject", "correct_response", "n_count", "prop")

#at the aggregated level
#knitr::kable(describe(prop_correct_vma_mem$prop[prop_correct_vma_mem$correct_response=="correct"]), digits = 2)

#tests
t_prop_vma_m = t.test(prop_correct_vma_mem$prop[prop_correct_vma_mem$correct_response=="correct"], mu = 0.5)
d_prop_vma_m = cohens_d(prop_correct_vma_mem$prop[prop_correct_vma_mem$correct_response=="correct"], mu = .5)

bf_prop_memory = bfrr(
  sample_mean = mean(prop_correct_vma_mem$prop[prop_correct_vma_mem$correct_response=="correct"])-.5, # mean of the sample minus the test value .5
  sample_se = sd(prop_correct_vma_mem$prop[prop_correct_vma_mem$correct_response=="correct"])/sqrt(length(prop_correct_vma_mem$prop[prop_correct_vma_mem$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_vma_mem$prop[prop_correct_vma_mem$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
)

#summary(bf_prop_memory)
```

```{r vma_correct_proportions_feeling, include=FALSE}
#proportion correct only for feeling attributions in the VMA
prop_correct_vma_feel = dat_vma %>% filter(attrib_buttons == "intuition_feeling_button") %>%
  group_by(subject, vma_correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(subject) %>% filter(!is.nan(freq))

colnames(prop_correct_vma_feel) = c("subject", "correct_response", "n_count", "prop")

#at the aggregated level
#knitr::kable(describe(prop_correct_vma_feel$prop[prop_correct_vma_feel$correct_response=="correct"]), digits = 2)

#tests
t_prop_vma_f = t.test(prop_correct_vma_feel$prop[prop_correct_vma_feel$correct_response=="correct"], mu = 0.5)
d_prop_vma_f = cohens_d(prop_correct_vma_feel$prop[prop_correct_vma_feel$correct_response=="correct"], mu = .5)

bf_prop_feel = bfrr(
  sample_mean = mean(prop_correct_vma_feel$prop[prop_correct_vma_feel$correct_response=="correct"])-.5, # mean of the sample minus the test value .5
  sample_se = sd(prop_correct_vma_feel$prop[prop_correct_vma_feel$correct_response=="correct"])/sqrt(length(prop_correct_vma_feel$prop[prop_correct_vma_feel$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_vma_feel$prop[prop_correct_vma_feel$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
)
#summary(bf_prop_feel)
```

```{r vma_correct_proportions_guessing, include=FALSE}
#proportion correct only for guess attributions in the VMA
prop_correct_vma_guess = dat_vma %>% filter(attrib_buttons == "guess_attrib_button") %>%
  group_by(subject, vma_correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(subject) %>% filter(!is.nan(freq))

colnames(prop_correct_vma_guess) = c("subject", "correct_response", "n_count", "prop")

#at the aggregated level
#knitr::kable(describe(prop_correct_vma_guess$prop[prop_correct_vma_guess$correct_response=="correct"]), digits = 2)

#tests
t_prop_vma_g = t.test(prop_correct_vma_guess$prop[prop_correct_vma_guess$correct_response=="correct"], mu = 0.5)
d_prop_vma_g = cohens_d(prop_correct_vma_guess$prop[prop_correct_vma_guess$correct_response=="correct"], mu = .5)

bf_prop_guess = bfrr(
  sample_mean = mean(prop_correct_vma_guess$prop[prop_correct_vma_guess$correct_response=="correct"])-.5, # mean of the sample minus the test value .5
  sample_se = sd(prop_correct_vma_guess$prop[prop_correct_vma_guess$correct_response=="correct"])/sqrt(length(prop_correct_vma_guess$prop[prop_correct_vma_guess$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_vma_guess$prop[prop_correct_vma_guess$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
)
#summary(bf_prop_guess)
```

```{r}
#### Valence memory accuracy as a function of attribution
# We conducted analyses with data from participants in the VMA task condition (*n =* `r length(unique(dat_vma$subject))`). 
# In the VMA task, after each valence memory response, participants had to attribute their response whether (1) to memory, (2) to a feeling of familiarity or intuition, or (3) to random guessing.
# 
# Overall, valence memory was above chance (*M =* `r mean(prop_correct_vma$prop[prop_correct_vma$correct_response=="correct"])`; *SD =* `r sd(prop_correct_vma$prop[prop_correct_vma$correct_response=="correct"])`), `r apa_print(t_prop_vma_o)$statistic`, *d =* `r d_prop_vma_o$Cohens_d`.
# This was also the case when participants made a memory attribution (*M =* `r mean(prop_correct_vma_mem$prop[prop_correct_vma_mem$correct_response=="correct"])`; *SD =* `r sd(prop_correct_vma_mem$prop[prop_correct_vma_mem$correct_response=="correct"])`), `r apa_print(t_prop_vma_m)$statistic`, *d =* `r d_prop_vma_m$Cohens_d`; 
# and when they made an intuition attribution (*M =* `r mean(prop_correct_vma_feel$prop[prop_correct_vma_feel$correct_response=="correct"])`; *SD =* `r sd(prop_correct_vma_feel$prop[prop_correct_vma_feel$correct_response=="correct"])`), `r apa_print(t_prop_vma_f)$statistic`, *d =* `r d_prop_vma_f$Cohens_d`. 
# 
# Valence memory performance was not significantly different from chance for random attributions (*M =* `r mean(prop_correct_vma_guess$prop[prop_correct_vma_guess$correct_response=="correct"])`; *SD =* `r sd(prop_correct_vma_guess$prop[prop_correct_vma_guess$correct_response=="correct"])`), `r apa_print(t_prop_vma_g)$statistic`, *d =* `r d_prop_vma_g$Cohens_d`, but BF yielded inconclusive evidence for or against chance-level performance, `r printBFRR(bf_prop_guess)`.

```


```{r overall_vma_figure, eval=FALSE, fig.cap="Difference between evaluative change scores for CS+ and CS- (EC scores) as a function of Attributions (VMA Task condition). Dots are the individual observations, and error bars are the 95% Confidence Intervals."}
dat_vma$attrib_plot = as.factor(recode(dat_vma$attrib_buttons, "guess_attrib_button"="random guessing"
       ,"intuition_feeling_button"="intuition"
       ,"memory_attrib_button"="memory"))

dat_vma$attrib_plot = fct_relevel(dat_vma$attrib_plot, "memory", "intuition", "random guessing")

dat_vma_plot = dat_vma %>%
  group_by(subject, us_valence, attrib_plot) %>%
  summarise(mean_eval_change = mean(eval_change_score)) 

dat_vma_plot_wide = dat_vma_plot %>% pivot_wider(names_from = us_valence
                                                 ,values_from = mean_eval_change)

dat_vma_plot_wide$EC_score = dat_vma_plot_wide$positive - dat_vma_plot_wide$negative

apa_beeplot(data=dat_vma_plot_wide, id="subject", dv="EC_score", factors="attrib_plot", intercept =0, use = "all.obs", ylim=c(-200,200)
            ,ylab = "Evaluative Conditioning effect score"
            ,xlab="Attribution")
```

```{r vma_eval_change_memory, include=FALSE}
####
#EVALUATIVE CHANGE AS A FUNCTION OF VALENCE MEMORY ATTRIBUTIONS IN THE VMA TASK
####

#for each attribution
###memory
dat_ev_vma_memory = dat_vma %>% filter(attrib_buttons == "memory_attrib_button") %>%
  group_by(subject, us_valence) %>%
  summarise(mean_eval_change = mean(eval_change_score)) %>% filter(n() > 1)

mod_memory_vma = aov_ez(dat_ev_vma_memory
                                ,id = "subject"
                                ,dv = "mean_eval_change"
                                ,within = "us_valence"
)

# mod_memory_vma_print = apa_print(mod_memory_vma)
# 
# apa_table(
#   mod_memory_vma_print$table
#   ,caption = "Repeated-measures ANOVA: Evaluative change scores as a function of US Valence for CSs that received a 'Memory' attribution in the Valence Memory Attribution task"
# )
# 
# knitr::kable(describeBy(dat_ev_vma_memory$mean_eval_change, dat_ev_vma_memory$us_valence, mat=TRUE), digits = 2)

dat_ev_vma_memory_wide = dat_ev_vma_memory %>% pivot_wider(names_from = "us_valence"
                                                                           ,values_from = "mean_eval_change")

dat_ev_vma_memory_wide$diff_overall = dat_ev_vma_memory_wide$positive-dat_ev_vma_memory_wide$negative 

dat_ev_vma_memory_wide = dat_ev_vma_memory_wide %>% filter(!is.na(diff_overall))

bf_ev_memory = bfrr(
  sample_mean = mean(dat_ev_vma_memory_wide$diff_overall), # mean of the sample
  sample_se = sd(dat_ev_vma_memory_wide$diff_overall)/sqrt(length(dat_ev_vma_memory_wide$diff_overall)), # SE of the sample
  sample_df = length(dat_ev_vma_memory_wide$diff_overall) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = 23.5,
  tail = 1,
  criterion = 3, 
  rr_interval = list(
    # mean = c(-2, 2),
    sd = c(0, 200)
  )
)

#summary(bf_ev_memory)
```

```{r vma_eval_change_intuition, include=FALSE}
###feeling
dat_ev_vma_feeling = dat_vma %>%  filter(attrib_buttons == "intuition_feeling_button") %>%
  group_by(subject, us_valence) %>%
  summarise(mean_eval_change = mean(eval_change_score)) %>% filter(n() > 1)

mod_feeling_vma = aov_ez(dat_ev_vma_feeling
                                 ,id = "subject"
                                 ,dv = "mean_eval_change"
                                 ,within = "us_valence"
)

# mod_feeling_vma_print = apa_print(mod_feeling_vma)
# 
# apa_table(
#   mod_feeling_vma_print$table
#   ,caption = "Repeated-measures ANOVA: Evaluative change scores as a function of US Valence for CSs that received an 'Intuition' attribution in the Valence Memory Attribution task"
# )
# 
# knitr::kable(describeBy(dat_ev_vma_feeling$mean_eval_change, dat_ev_vma_feeling$us_valence, mat=TRUE), digits=2)

dat_ev_vma_feeling_wide = dat_ev_vma_feeling %>% pivot_wider(names_from = "us_valence"
                                                                             ,values_from = "mean_eval_change")

dat_ev_vma_feeling_wide$diff_overall = dat_ev_vma_feeling_wide$positive-dat_ev_vma_feeling_wide$negative 

dat_ev_vma_feeling_wide = dat_ev_vma_feeling_wide %>% filter(!is.na(diff_overall))

bf_ev_feeling = bfrr(
  sample_mean = mean(dat_ev_vma_feeling_wide$diff_overall), # mean of the sample
  sample_se = sd(dat_ev_vma_feeling_wide$diff_overall)/sqrt(length(dat_ev_vma_feeling_wide$diff_overall)), # SE of the sample
  sample_df = length(dat_ev_vma_feeling_wide$diff_overall) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = 23.5,
  tail = 1,
  criterion = 3, 
  rr_interval = list(
    # mean = c(-2, 2),
    sd = c(0, 200)
  )
)

#summary(bf_ev_feeling)
```

```{r vma_eval_change_guessing, include=FALSE}
###guess
dat_ev_vma_guess = dat_vma %>% filter(attrib_buttons == "guess_attrib_button") %>%
  group_by(subject, us_valence) %>%
  summarise(mean_eval_change = mean(eval_change_score)) %>% filter(n() > 1)

mod_guess_vma = aov_ez(dat_ev_vma_guess
                               ,id = "subject"
                               ,dv = "mean_eval_change"
                               ,within = "us_valence"
)

# mod_guess_vma_print = apa_print(mod_guess_vma)
# 
# apa_table(
#   mod_guess_vma_print$table
#   ,caption = "Repeated-measures ANOVA: Evaluative change scores as a function of US Valence for CSs that received a 'Guess' attribution in the Valence Memory Attribution task"
# )
# 
# knitr::kable(describeBy(dat_ev_vma_guess$mean_eval_change, dat_ev_vma_guess$us_valence, mat=TRUE), digits=2)

dat_ev_vma_guess_wide = dat_ev_vma_guess %>% pivot_wider(names_from = "us_valence"
                                                                         ,values_from = "mean_eval_change")

dat_ev_vma_guess_wide$diff_overall = dat_ev_vma_guess_wide$positive-dat_ev_vma_guess_wide$negative 

dat_ev_vma_guess_wide = dat_ev_vma_guess_wide %>% filter(!is.na(diff_overall))

bf_ev_guess = bfrr(
  sample_mean = mean(dat_ev_vma_guess_wide$diff_overall), # mean of the sample
  sample_se = sd(dat_ev_vma_guess_wide$diff_overall)/sqrt(length(dat_ev_vma_guess_wide$diff_overall)), # SE of the sample
  sample_df = length(dat_ev_vma_guess_wide$diff_overall) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = 23.5,
  tail = 1,
  criterion = 3, 
  rr_interval = list(
    # mean = c(-2, 2),
    sd = c(0, 200)
  )
)

#summary(bf_ev_guess)
#plot(bf_ev_guess)
```

```{r vma_eval_change_no_struct_k, include=FALSE}
#recode intuition and guessing attributions into "no_conscious_s_k"
dat_vma = dat_vma %>% mutate(recode_attrib = as.factor(ifelse(attrib_buttons=="memory_attrib_button", "conscious", "no_conscious_sk")))

#check whether it worked as intended
table(dat_vma$attrib_buttons, dat_vma$recode_attrib)
  
#for no conscious structural knowledge (intuition and guessing)
dat_ev_vma_no_conscious = dat_vma %>% filter(recode_attrib == "no_conscious_sk") %>%
  group_by(subject, us_valence) %>%
  summarise(mean_eval_change = mean(eval_change_score)) %>% filter(n() > 1)

mod_noc_vma = aov_ez(dat_ev_vma_no_conscious
                                ,id = "subject"
                                ,dv = "mean_eval_change"
                                ,within = "us_valence"
)

# mod_noc_vma_print = apa_print(mod_noc_vma)
# 
# apa_table(
#   mod_noc_vma_print$table
#   ,caption = "Repeated-measures ANOVA: Evaluative change scores as a function of US Valence for CSs that received an 'Intuition' or 'Guess' (no conscious structural knowledge) attribution in the Valence Memory Attribution task"
# )
# 
# knitr::kable(describeBy(dat_ev_vma_no_conscious$mean_eval_change, dat_ev_vma_no_conscious$us_valence, mat=TRUE), digits=2)

dat_ev_vma_no_conscious_wide = dat_ev_vma_no_conscious %>% pivot_wider(names_from = "us_valence"
                                                                           ,values_from = "mean_eval_change")

dat_ev_vma_no_conscious_wide$diff_overall = dat_ev_vma_no_conscious_wide$positive-dat_ev_vma_no_conscious_wide$negative 

dat_ev_vma_no_conscious_wide = dat_ev_vma_no_conscious_wide %>% filter(!is.na(diff_overall))

bf_ev_no_conscious = bfrr(
  sample_mean = mean(dat_ev_vma_no_conscious_wide$diff_overall), # mean of the sample
  sample_se = sd(dat_ev_vma_no_conscious_wide$diff_overall)/sqrt(length(dat_ev_vma_no_conscious_wide$diff_overall)), # SE of the sample
  sample_df = length(dat_ev_vma_no_conscious_wide$diff_overall) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = 23.5,
  tail = 1,
  criterion = 3, 
  rr_interval = list(
    # mean = c(-2, 2),
    sd = c(0, 200)
  )
)

#summary(bf_ev_no_conscious)
#plot(bf_ev_no_conscious)
```

<!-- #### EC effects as a function of attribution -->

We tested whether we replicate Waroquier et al.'s (2020) findings. 
<!-- The main results are displayed in Figure \@ref(fig:overall_vma_figure).  -->
In particular, we were interested in whether we find an EC effect when participants reported no memory (random guessing).
Because the VMA task only assesses valence memory (not evaluations), EC effects were computed as pre-post differences in evaluative ratings as in Waroquier et al. (2020).

We found an EC effect when participants made a memory attribution, `r apa_print(mod_memory_vma)$full_result`. 
When participants made an intuition attribution, the EC effect was not significant, `r apa_print(mod_feeling_vma)$full_result`, and BF was inconclusive, `r printBFRR(bf_ev_feeling)`. ^[We used the same *H1* prior distribution as Waroquier et al. (2020), who expected EC effects of approximately 23.5 liking units on a 400 point scale.]

Critically and contrary to Waroquier et al. (2020), we found no EC effect when participants made a random guessing attribution, `r apa_print(mod_guess_vma)$full_result`, and BF yielded evidence against an EC effect, `r printBFRR(bf_ev_guess)`. ^[As done by Waroquier et al., we grouped intuition and random attributions into a single "no conscious structural knowledge" category. 
We did not find an EC effect for this category, `r apa_print(mod_noc_vma)$full_result`, and BF yielded evidence against it, `r printBFRR(bf_ev_no_conscious)`.] 

#### Three-attribution, continuous evaluation (3ACE) task

```{r 3bs, include=FALSE}
####
#3BS PROCEDURE (3BS in analysis is analogous to 3ACE in text)
####

#keep only participants that performed the TBS
dat_3bs = dat %>% filter(eval_task == "3BS_study") %>% droplevels()

length(unique(dat_3bs$subject)) #52 participants

dat_3bs$scales_3BS_state = as.factor(dat_3bs$scales_3BS_state)

dat_3bs$scale_3bs_intuition = as.numeric(dat_3bs$scale_3bs_intuition)
dat_3bs$scale_3bs_guess = as.numeric(dat_3bs$scale_3bs_guess)

#for each participant, compute the proportion of correct identifications in the 3BS
#meaning, say "positive" if the CS was paired with a positive US, and say "negative if the CS was paired with a negative US
dat_3bs$correct = NA

#first, compute correct responses
dat_3bs$correct[dat_3bs$scales_3BS_state=="memory_button"] = ifelse(substr(dat_3bs$us_valence[dat_3bs$scales_3BS_state=="memory_button"], 1, 3) == substr(dat_3bs$response_3bs[dat_3bs$scales_3BS_state=="memory_button"], 1, 3), "correct", "incorrect")

#recode the responses on the intuition and guess scale so that negative scores
##indicate "negative" and positive scores indicate "positive"
dat_3bs$recode_intuition_scale = NA
dat_3bs$recode_intuition_scale[dat_3bs$scales_3BS_state=="intuition_scale"] = ifelse(dat_3bs$scale_3bs_intuition[dat_3bs$scales_3BS_state=="intuition_scale"] > 0, "pos", ifelse(dat_3bs$scale_3bs_intuition[dat_3bs$scales_3BS_state=="intuition_scale"] < 0, "neg", 0))

dat_3bs$recode_guess_scale = NA
dat_3bs$recode_guess_scale[dat_3bs$scales_3BS_state=="guess_scale"] = ifelse(dat_3bs$scale_3bs_guess[dat_3bs$scales_3BS_state=="guess_scale"] > 0, "pos", ifelse(dat_3bs$scale_3bs_guess[dat_3bs$scales_3BS_state=="guess_scale"] < 0, "neg", 0))

dat_3bs$correct[dat_3bs$scales_3BS_state=="intuition_scale"] = ifelse(substr(dat_3bs$us_valence[dat_3bs$scales_3BS_state=="intuition_scale"], 1, 3) == dat_3bs$recode_intuition_scale[dat_3bs$scales_3BS_state=="intuition_scale"], "correct", "incorrect")

dat_3bs$correct[dat_3bs$scales_3BS_state=="guess_scale"] = ifelse(substr(dat_3bs$us_valence[dat_3bs$scales_3BS_state=="guess_scale"], 1, 3) == dat_3bs$recode_guess_scale[dat_3bs$scales_3BS_state=="guess_scale"], "correct", "incorrect")

dat_3bs$correct = as.factor(dat_3bs$correct)

#saveRDS(dat_3bs, "data/appendix/appendix_exp3_3ace.RDS")

#compute the difference between pre- and post-ratings for each CS in the 3ACE task
dat_eval_change_intuition = subset(dat_3bs, scales_3BS_state=="intuition_scale") %>%
  group_by(subject, c, u, scales_3BS_state, us_valence) %>%
  summarise(eval_change_score_3bs_intuition = scale_3bs_intuition - scale_prerating)

dat_eval_change_guess = subset(dat_3bs, scales_3BS_state=="guess_scale") %>%
  group_by(subject, c, u, scales_3BS_state, us_valence) %>%
  summarise(eval_change_score_3bs_guess = scale_3bs_guess - scale_prerating)

#for analyses with intuition and guessing grouped together, create another dataset
dat_intui_guess = full_join(dat_eval_change_intuition, dat_eval_change_guess
                , by = c("subject"="subject", "scales_3BS_state"="scales_3BS_state",
                         "us_valence"="us_valence", "c"="c", "u"="u")) 

#put scores into the same column
dat_intui_guess$eval_change_score_3bs_intuition_guess = coalesce(dat_intui_guess$eval_change_score_3bs_intuition, dat_intui_guess$eval_change_score_3bs_guess)
```

```{r 3bs_correct_proportions_overall, include=FALSE}
#proportion of correct responses
prop_correct_3bs = dat_3bs %>% 
  group_by(subject, correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(subject) %>% filter(!is.nan(freq))

colnames(prop_correct_3bs) = c("subject", "correct_response", "n_count", "prop")

#at the aggregated level
#knitr::kable(describe(prop_correct_3bs$prop[prop_correct_3bs$correct_response=="correct"]), digits=2)

#tests
t_prop_3bs_o = t.test(prop_correct_3bs$prop[prop_correct_3bs$correct_response=="correct"], mu = 0.5)
d_prop_3bs_o = cohens_d(prop_correct_3bs$prop[prop_correct_3bs$correct_response=="correct"], mu = .5)

bf_prop_overall_3bs = bfrr(
  sample_mean = mean(prop_correct_3bs$prop[prop_correct_3bs$correct_response=="correct"])-.5, # mean of the sample
  sample_se = sd(prop_correct_3bs$prop[prop_correct_3bs$correct_response=="correct"])/sqrt(length(prop_correct_3bs$prop[prop_correct_3bs$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_3bs$prop[prop_correct_3bs$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
)
#summary(bf_prop_overall_3bs)
```

```{r 3bs_correct_proportions_memory, include=FALSE}
#proportion of correct memory attributions
prop_correct_3bs_mem = dat_3bs %>% filter(scales_3BS_state == "memory_button") %>%
  group_by(subject, correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(subject) %>% filter(!is.nan(freq))

colnames(prop_correct_3bs_mem) = c("subject", "correct_response", "n_count", "prop")

#tests
t_prop_3bs_m = t.test(prop_correct_3bs_mem$prop[prop_correct_3bs_mem$correct_response=="correct"], mu = 0.5)
d_prop_3bs_m = cohens_d(prop_correct_3bs_mem$prop[prop_correct_3bs_mem$correct_response=="correct"], mu = .5)

bf_prop_mem_3bs = bfrr(
  sample_mean = mean(prop_correct_3bs_mem$prop[prop_correct_3bs_mem$correct_response=="correct"])-.5, # mean of the sample
  sample_se = sd(prop_correct_3bs_mem$prop[prop_correct_3bs_mem$correct_response=="correct"])/sqrt(length(prop_correct_3bs_mem$prop[prop_correct_3bs_mem$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_3bs_mem$prop[prop_correct_3bs_mem$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
)
#summary(bf_prop_mem_3bs)
```

```{r 3bs_correct_proportions_intuition, include=FALSE}
#proportion of correct intuition scale uses
prop_correct_3bs_intuition = dat_3bs %>% filter(scales_3BS_state == "intuition_scale") %>%
  group_by(subject, correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(subject) %>% filter(!is.nan(freq))

colnames(prop_correct_3bs_intuition) = c("subject", "correct_response", "n_count", "prop")

#at the aggregated level
#knitr::kable(describe(prop_correct_3bs_intuition$prop[prop_correct_3bs_intuition$correct_response=="correct"]), digits=2)

#tests
t_prop_3bs_i = t.test(prop_correct_3bs_intuition$prop[prop_correct_3bs_intuition$correct_response=="correct"], mu = 0.5)
d_prop_3bs_i = cohens_d(prop_correct_3bs_intuition$prop[prop_correct_3bs_intuition$correct_response=="correct"], mu = .5)

bf_prop_intuition_3bs = bfrr(
  sample_mean = mean(prop_correct_3bs_intuition$prop[prop_correct_3bs_intuition$correct_response=="correct"])-.5, # mean of the sample
  sample_se = sd(prop_correct_3bs_intuition$prop[prop_correct_3bs_intuition$correct_response=="correct"])/sqrt(length(prop_correct_3bs_intuition$prop[prop_correct_3bs_intuition$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_3bs_intuition$prop[prop_correct_3bs_intuition$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
)
#summary(bf_prop_intuition_3bs)
```

```{r 3bs_correct_proportions_guessing, include=FALSE}
#proportion of correct guess scale uses
prop_correct_3bs_guess = dat_3bs %>% filter(scales_3BS_state == "guess_scale") %>%
  group_by(subject, correct, .drop=FALSE) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>% group_by(subject) %>% filter(!is.nan(freq))

colnames(prop_correct_3bs_guess) = c("subject", "correct_response", "n_count", "prop")

#at the aggregated level
#knitr::kable(describe(prop_correct_3bs_guess$prop[prop_correct_3bs_guess$correct_response=="correct"]), digits=2)

#tests
t_prop_3bs_g = t.test(prop_correct_3bs_guess$prop[prop_correct_3bs_guess$correct_response=="correct"], mu = 0.5)
d_prop_3bs_g = cohens_d(prop_correct_3bs_guess$prop[prop_correct_3bs_guess$correct_response=="correct"], mu = .5)

bf_prop_guess_3bs = bfrr(
  sample_mean = mean(prop_correct_3bs_guess$prop[prop_correct_3bs_guess$correct_response=="correct"])-.5, # mean of the sample
  sample_se = sd(prop_correct_3bs_guess$prop[prop_correct_3bs_guess$correct_response=="correct"])/sqrt(length(prop_correct_3bs_guess$prop[prop_correct_3bs_guess$correct_response=="correct"])), # SE of the sample
  sample_df = length(prop_correct_3bs_guess$prop[prop_correct_3bs_guess$correct_response=="correct"]) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = .15, 
  tail = 1, #one-tailed
  criterion = 3, 
  rr_interval = list( # ranges to vary H1 parameters for robustness regions
    sd = c(0, 1) 
  )
)
#summary(bf_prop_guess_3bs)
```

```{r}
#### Valence memory accuracy as a function of response set

# We repeated the analyses we conducted in the VMA task on data from the 3ACE procedure (*n =* `r length(unique(dat_3bs$subject))`). As noted above, the 3ACE procedure is aimed to illustrate how the TBS procedure can be adapted. In the 3ACE, the TBS procedure's Attitude responses buttons set was replaced by two scales to get closer to the three response options from Waroquier et al.'s (2020) VMA: a feeling/intuition scale and a random guessing scale. 
# 
# Overall, valence memory was above chance (*M =* `r mean(prop_correct_3bs$prop[prop_correct_3bs$correct_response=="correct"])`; *SD =* `r sd(prop_correct_3bs$prop[prop_correct_3bs$correct_response=="correct"])`), `r apa_print(t_prop_3bs_o)$statistic`, *d =* `r d_prop_3bs_o$Cohens_d`. 
# This was also the case when participants used the Memory response buttons set (*M =* `r mean(prop_correct_3bs_mem$prop[prop_correct_3bs_mem$correct_response=="correct"])`; *SD =* `r sd(prop_correct_3bs_mem$prop[prop_correct_3bs_mem$correct_response=="correct"])`), `r apa_print(t_prop_3bs_m)$statistic`, *d =* `r d_prop_3bs_m$Cohens_d`. 
# Diverging from results on the VMA task, when participants used the feeling/intuition set, performance was not significantly above chance, but BF was inconclusive (*M =* `r mean(prop_correct_3bs_intuition$prop[prop_correct_3bs_intuition$correct_response=="correct"])`; *SD =* `r sd(prop_correct_3bs_intuition$prop[prop_correct_3bs_intuition$correct_response=="correct"])`), `r apa_print(t_prop_3bs_i)$statistic`, *d =* `r d_prop_3bs_i$Cohens_d`, `r printBFRR(bf_prop_intuition_3bs)`. 
# In line with the VMA results, valence memory performance was not significantly different from chance for random-guessing attributions (*M =* `r mean(prop_correct_3bs_guess$prop[prop_correct_3bs_guess$correct_response=="correct"])`; *SD =* `r sd(prop_correct_3bs_guess$prop[prop_correct_3bs_guess$correct_response=="correct"])`), `r apa_print(t_prop_3bs_g)$statistic`, *d =* `r d_prop_3bs_g$Cohens_d`, and BF yielded evidence for chance-level performance, `r printBFRR(bf_prop_guess_3bs)`. 

```

```{r 3bs_eval_change_memory, include=FALSE}
####
#EVALUATIVE CHANGE AS A FUNCTION OF VALENCE MEMORY ATTRIBUTIONS IN THE 3BS TASK
####

###memory button
dat_ev_3bs_memory = dat_3bs %>%  filter(scales_3BS_state == "memory_button") %>%
  group_by(subject, us_valence) %>%
  summarise(mean_eval_change = mean(eval_change_score)) %>% filter(n() > 1)

mod_memory_3bs = aov_ez(dat_ev_3bs_memory
                                ,id = "subject"
                                ,dv = "mean_eval_change"
                                ,within = "us_valence"
)

# mod_memory_3bs_print = apa_print(mod_memory_3bs)
# 
# apa_table(
#   mod_memory_3bs_print$table
#   ,caption = "Repeated-measures ANOVA: Evaluative change scores as a function of US Valence for CSs that received a memory-buttons set response (3BS procedure)"
# )
# 
# 
# knitr::kable(describeBy(dat_ev_3bs_memory$mean_eval_change, dat_ev_3bs_memory$us_valence, mat=TRUE), digits=2)

dat_ev_3bs_memory_wide = dat_ev_3bs_memory %>% pivot_wider(names_from = "us_valence"
                                                                           ,values_from = "mean_eval_change")

dat_ev_3bs_memory_wide$diff_overall = dat_ev_3bs_memory_wide$positive-dat_ev_3bs_memory_wide$negative 

dat_ev_3bs_memory_wide = dat_ev_3bs_memory_wide %>% filter(!is.na(diff_overall))

bf_ev_memory_3bs = bfrr(
  sample_mean = mean(dat_ev_3bs_memory_wide$diff_overall), # mean of the sample
  sample_se = sd(dat_ev_3bs_memory_wide$diff_overall)/sqrt(length(dat_ev_3bs_memory_wide$diff_overall)), # SE of the sample
  sample_df = length(dat_ev_3bs_memory_wide$diff_overall) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = 23.5,
  tail = 1,
  criterion = 3, 
  rr_interval = list(
    # mean = c(-2, 2),
    sd = c(0, 200)
  )
)

#summary(bf_ev_memory_3bs)
```

```{r 3bseval_change_intuition_3ace_ratings, include=FALSE}
##intuition scale
dat_ev_3bs_intuition_3ace_ratings = dat_eval_change_intuition %>%
  group_by(subject, us_valence) %>%
  summarise(mean_eval_change = mean(eval_change_score_3bs_intuition)) %>% filter(n() > 1)

mod_intuition_3bs_3ace_ratings = aov_ez(dat_ev_3bs_intuition_3ace_ratings
                                   ,id = "subject"
                                   ,dv = "mean_eval_change"
                                   ,within = "us_valence"
)

dat_ev_3bs_intuition_wide_3ace_ratings = dat_ev_3bs_intuition_3ace_ratings %>% pivot_wider(names_from = "us_valence"
                     ,values_from = "mean_eval_change")

dat_ev_3bs_intuition_wide_3ace_ratings$diff_overall = dat_ev_3bs_intuition_wide_3ace_ratings$positive-dat_ev_3bs_intuition_wide_3ace_ratings$negative 
dat_ev_3bs_intuition_wide_3ace_ratings = dat_ev_3bs_intuition_wide_3ace_ratings %>% filter(!is.na(diff_overall))

bf_ev_intuition_3bs_3ace_ratings = bfrr(
  sample_mean = mean(dat_ev_3bs_intuition_wide_3ace_ratings$diff_overall), # mean of the sample
  sample_se = sd(dat_ev_3bs_intuition_wide_3ace_ratings$diff_overall)/sqrt(length(dat_ev_3bs_intuition_wide_3ace_ratings$diff_overall)), # SE of the sample
  sample_df = length(dat_ev_3bs_intuition_wide_3ace_ratings$diff_overall) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = 23.5,
  tail = 1,
  criterion = 3, 
  rr_interval = list(
    # mean = c(-2, 2),
    sd = c(0, 200)
  )
)

# summary(bf_ev_intuition_3bs_3ace_ratings)
```

```{r 3bs_eval_change_guessing_3ace_ratings, include=FALSE}
##guess scale
dat_ev_3bs_guess_3ace_ratings = dat_eval_change_guess %>%
  group_by(subject, us_valence) %>%
  summarise(mean_eval_change = mean(eval_change_score_3bs_guess)) %>% filter(n() > 1)

mod_guess_3bs_3ace_ratings = aov_ez(dat_ev_3bs_guess_3ace_ratings
                               ,id = "subject"
                               ,dv = "mean_eval_change"
                               ,within = "us_valence"
)

dat_ev_3bs_guess_wide_3ace_ratings = dat_ev_3bs_guess_3ace_ratings %>% pivot_wider(names_from = "us_valence"
            ,values_from = "mean_eval_change")

dat_ev_3bs_guess_wide_3ace_ratings$diff_overall = dat_ev_3bs_guess_wide_3ace_ratings$positive-dat_ev_3bs_guess_wide_3ace_ratings$negative 

dat_ev_3bs_guess_wide_3ace_ratings = dat_ev_3bs_guess_wide_3ace_ratings %>% filter(!is.na(diff_overall))

bf_ev_guess_3bs_3ace_ratings = bfrr(
  sample_mean = mean(dat_ev_3bs_guess_wide_3ace_ratings$diff_overall), # mean of the sample
  sample_se = sd(dat_ev_3bs_guess_wide_3ace_ratings$diff_overall)/sqrt(length(dat_ev_3bs_guess_wide_3ace_ratings$diff_overall)), # SE of the sample
  sample_df = length(dat_ev_3bs_guess_wide_3ace_ratings$diff_overall) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = 23.5,
  tail = 1,
  criterion = 3, 
  rr_interval = list(
    # mean = c(-2, 2),
    sd = c(0, 200)
  )
)

# summary(bf_ev_guess_3bs_3ace_ratings)
```

```{r 3bs_eval_change_no_struct_k_3ace_ratings, include=FALSE}
#for no conscious structural knowledge (intuition and guessing)
dat_ev_3bs_no_conscious_3ace_ratings = dat_intui_guess %>%
  group_by(subject, us_valence) %>%
  summarise(mean_eval_change = mean(eval_change_score_3bs_intuition_guess)) %>% filter(n() > 1)

mod_noc_3bs_3ace_ratings = aov_ez(dat_ev_3bs_no_conscious_3ace_ratings
                                ,id = "subject"
                                ,dv = "mean_eval_change"
                                ,within = "us_valence"
)

dat_ev_3bs_no_conscious_wide_3ace_ratings = dat_ev_3bs_no_conscious_3ace_ratings %>% pivot_wider(names_from = "us_valence"
            ,values_from = "mean_eval_change")

dat_ev_3bs_no_conscious_wide_3ace_ratings$diff_overall = dat_ev_3bs_no_conscious_wide_3ace_ratings$positive-dat_ev_3bs_no_conscious_wide_3ace_ratings$negative 

dat_ev_3bs_no_conscious_wide_3ace_ratings = dat_ev_3bs_no_conscious_wide_3ace_ratings %>% filter(!is.na(diff_overall))

bf_ev_no_conscious_3bs_3ace_ratings = bfrr(
  sample_mean = mean(dat_ev_3bs_no_conscious_wide_3ace_ratings$diff_overall), # mean of the sample
  sample_se = sd(dat_ev_3bs_no_conscious_wide_3ace_ratings$diff_overall)/sqrt(length(dat_ev_3bs_no_conscious_wide_3ace_ratings$diff_overall)), # SE of the sample
  sample_df = length(dat_ev_3bs_no_conscious_wide_3ace_ratings$diff_overall) - 1, # degrees of freedom
  model = "normal",
  mean = 0, 
  sd = 23.5,
  tail = 1,
  criterion = 3, 
  rr_interval = list(
    # mean = c(-2, 2),
    sd = c(0, 200)
  )
)

# summary(bf_ev_no_conscious_3bs_3ace_ratings)
```

<!-- #### EC effects as a function of response set -->

<!-- We were interested in whether we find an EC effect when participants reported no memory (random guessing), as in the VMA task.  -->
In the 3ACE data, we found an EC effect when participants made a memory attribution, `r apa_print(mod_memory_3bs)$full_result`.
<!-- , `r printBFRR(bf_ev_memory_3bs)`.  -->
When participants made a feeling/intuition attribution, the EC effect was also significant, `r apa_print(mod_intuition_3bs_3ace_ratings)$full_result`.
<!-- , and the BF yielded evidence for an EC effect, `r printBFRR(bf_ev_intuition_3bs_3ace_ratings)`.  -->
We found no EC effect when participants made a random-guessing attribution, `r apa_print(mod_guess_3bs_3ace_ratings)$full_result`, and the BF yielded evidence against an EC effect, `r printBFRR(bf_ev_guess_3bs_3ace_ratings)`. 
^[When feeling/intuition and random guessing responses were grouped into a single "no conscious structural knowledge" category, we did not find an EC effect, `r apa_print(mod_noc_3bs_3ace_ratings)$full_result`, but the BF was inconclusive, `r printBFRR(bf_ev_no_conscious_3bs_3ace_ratings)`.]
